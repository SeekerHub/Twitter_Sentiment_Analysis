{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_data_preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5K2Pi-IvMCn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Yj828JmvXd3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = pd.read_csv('/content/train_2kmZucJ.csv',)\n",
        "train_data = train_data.reset_index(drop = True)\n",
        "test_data = pd.read_csv('/content/test_oJQbWVk.csv')\n",
        "test_data = test_data.reset_index(drop = True)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syeB3JpmwXu5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4f5bb0ec-e189-45a8-c2c3-32c7cf258dde"
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7920, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0xqJ2zZSGwr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5805defd-8ce8-4554-d686-f3ed1e941d94"
      },
      "source": [
        "test_data.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1953, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6td5pVRwSQn4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "ef1ff140-d3d4-4f8d-ba36-40ecccfe6c03"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>#fingerprint #Pregnancy Test https://goo.gl/h1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Finally a transparant silicon case ^^ Thanks t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>We love this! Would you go? #talk #makememorie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>I'm wired I know I'm George I was made that wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>What amazing service! Apple won't even talk to...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label                                              tweet\n",
              "0   1      0  #fingerprint #Pregnancy Test https://goo.gl/h1...\n",
              "1   2      0  Finally a transparant silicon case ^^ Thanks t...\n",
              "2   3      0  We love this! Would you go? #talk #makememorie...\n",
              "3   4      0  I'm wired I know I'm George I was made that wa...\n",
              "4   5      1  What amazing service! Apple won't even talk to..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UCf284SQpAu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "ba7698f3-5b1f-4bb4-994d-9735db8da4f3"
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "import string\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGppbclMFhNy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "271fa284-13fb-4d50-9141-77e9cd42de0a"
      },
      "source": [
        "#HappyEmoticons\n",
        "emoticons_happy = set([\n",
        "    ':-)', ':)', ';)', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)', ':}',\n",
        "    ':^)', ':-D', ':D', '8-D', '8D', 'x-D', 'xD', 'X-D', 'XD', '=-D', '=D',\n",
        "    '=-3', '=3', ':-))', \":'-)\", \":')\", ':*', ':^*', '>:P', ':-P', ':P', 'X-P',\n",
        "    'x-p', 'xp', 'XP', ':-p', ':p', '=p', ':-b', ':b', '>:)', '>;)', '>:-)',\n",
        "    '<3'\n",
        "    ])\n",
        "\n",
        "#Sad emoticons\n",
        "emoticons_sad = set([\n",
        "    ':L', ':-/', '>:/', ':S', '>:[', ':@', ':-(', ':[', ':-||', '=L', ':<',\n",
        "    ':-[', ':-<', '=\\\\', '=/', '>:(', ':(', '>.<', \":'-(\", \":'(\", ':\\\\', ':-c',\n",
        "    ':c', ':{', '>:\\\\', ';('\n",
        "    ])\n",
        "\n",
        "emoticons = emoticons_happy.union(emoticons_sad)\n",
        "\n",
        "!pip install tweet-preprocessor"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tweet-preprocessor in /usr/local/lib/python3.6/dist-packages (0.6.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUXKuIquJ_OU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Emoji patterns\n",
        "emoji_pattern = re.compile(\"[\"\n",
        "         u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "         u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "         u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "         u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "         u\"\\U00002702-\\U000027B0\"\n",
        "         u\"\\U000024C2-\\U0001F251\"\n",
        "         \"]+\", flags=re.UNICODE)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PCOYJhDIJqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "def clean_tweets(tweet):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    word_tokens = word_tokenize(tweet)#after tweepy preprocessing the colon symbol left remain after      #removing mentions\n",
        "    tweet = re.sub(r':', '', tweet)\n",
        "    tweet = re.sub(r'‚Ä¶', '', tweet)\n",
        "#replace consecutive non-ASCII characters with a space\n",
        "    tweet = re.sub(r'[^\\x00-\\x7F]+',' ', tweet)#remove emojis from tweet\n",
        "    tweet = emoji_pattern.sub(r'', tweet)#filter using NLTK library append it to a string\n",
        "    filtered_tweet = [w for w in word_tokens if not w in stop_words]\n",
        "    filtered_tweet = []#looping through conditions\n",
        "    for w in word_tokens:\n",
        "      #check tokens against stop words , emoticons and punctuations\n",
        "      if w not in stop_words and w not in emoticons and w not in string.punctuation:\n",
        "        filtered_tweet.append(w)\n",
        "    return ' '.join(filtered_tweet)\n",
        "\n",
        "round1 = lambda x: clean_tweets(x)   "
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dw393hF1KdqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_urls(vTEXT):\n",
        "    vTEXT = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', vTEXT, flags=re.MULTILINE)\n",
        "    return(vTEXT)\n",
        "\n",
        "round2 = lambda x: remove_urls(x) \n",
        "\n",
        "def clean_text_round2(text):\n",
        "    '''Get rid of some additional punctuation and non-sensical text that was missed the first time around.'''\n",
        "    text = re.sub('[‘’“”…]', '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    return text\n",
        "\n",
        "round3 = lambda x: clean_text_round2(x)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IW52VInzIn22",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "c469869d-29ea-4e9a-9eb4-5a5b42f7d254"
      },
      "source": [
        "data_clean = pd.DataFrame(train_data.tweet.apply(round2))\n",
        "data_clean = pd.DataFrame(data_clean.tweet.apply(round1))\n",
        "data_clean.tweet[]"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'We love Would go talk makememories unplug relax iphone smartphone wifi connect ...'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yfwhwe0bJ-Xt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_clean =  pd.DataFrame(data_clean.tweet.apply(round3))\n",
        "# data_clean.tweet[]"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EE16HutkeLcR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d3afd7db-587f-4982-9ceb-f6ae58e1539f"
      },
      "source": [
        "data_clean.tweet[2]"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'We love Would go talk makememories unplug relax iphone smartphone wifi connect ...'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OHXyeADBEkK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_round_1(text):\n",
        "  corpus = []\n",
        "  text = re.sub(r'[^a-zA-Z]', ' ', data['tweet'][i])\n",
        "  text = text.lower()\n",
        "  text = text.split()\n",
        "  \"\"\"Applying Steming\"\"\"\n",
        "  all_stopwords = stopwords.words('english')\n",
        "  all_stopwords.remove('not')\n",
        "  ps = PorterStemmer() #loved --> love word thast essentially means the same\n",
        "  text = [ps.stem(word) for word in text if not word in set(all_stopwords)]\n",
        "  corpus = ' '.join(text)\n",
        "  return corpus\n",
        "\n",
        "round1 = lambda x: clean_round_1(x)\n",
        "\n",
        "def clean_round_2(text):\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text) \n",
        "\n",
        "round1 = lambda x: clean_round_2(x)\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gda2GoGq-Upy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "9198701b-ed07-4bb1-b338-5c39ef0db26e"
      },
      "source": [
        "print(corp)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['seri escapad demonstr adag good goos also good gander occasion amus none amount much stori', 'seri escapad demonstr adag good goos', 'seri', '', 'seri', 'escapad demonstr adag good goos', '', 'escapad demonstr adag good goos', 'escapad', 'demonstr adag good goos', 'demonstr adag', 'demonstr', 'adag', '', 'adag', 'good goos', '', 'good goos', '', 'good goos', '', 'good goos', 'good', 'goos', '', 'goos', 'goos', 'also good gander occasion amus none amount much stori', 'also good gander occasion amus none amount much stori', 'also', 'also', 'good gander occasion amus none amount much stori', 'gander occasion amus none amount much stori', 'gander occasion amus none amount much stori', 'gander', 'gander', 'gander', '', 'occasion amus none amount much stori', '', '', '', '', 'occasion amus none amount much stori', 'occasion', 'amus none amount much stori', 'amus', 'none amount much stori', '', 'none amount much stori', 'none', 'amount much stori', 'amount much stori', 'amount much stori', 'amount', 'much stori', '', 'much stori', 'much', 'stori', 'stori', 'stori', '', 'quiet introspect entertain independ worth seek', 'quiet introspect entertain independ', '', 'quiet introspect entertain independ', 'quiet introspect entertain', 'quiet', 'introspect entertain', 'introspect entertain', 'introspect', 'introspect', '', 'entertain', 'independ', 'worth seek', 'worth seek', 'worth', 'worth', 'seek', 'even fan ismail merchant work suspect would hard time sit one', 'even fan ismail merchant work', 'even fan', 'even', 'fan', 'ismail merchant work', 'ismail merchant work', 'ismail merchant', 'ismail', 'merchant', 'merchant', '', 'work', 'suspect would hard time sit one', 'suspect', 'suspect', 'suspect', '', 'suspect', 'would hard time sit one', 'would hard time sit one', 'would', 'hard time sit one', '', 'hard time sit one', 'hard time', 'hard time', 'hard', 'time', 'sit one', 'sit', 'one', '', 'one', 'one', 'posit thrill combin ethnographi intrigu betray deceit murder shakespearean tragedi juici soap opera', 'posit thrill combin ethnographi intrigu betray deceit murder shakespearean tragedi juici soap opera', 'posit thrill combin ethnographi intrigu betray deceit murder', 'posit thrill combin', 'posit thrill combin', 'posit', 'thrill combin', 'thrill', 'combin', 'ethnographi intrigu betray deceit murder', 'ethnographi intrigu betray deceit murder', 'ethnographi', 'ethnographi', 'intrigu betray deceit murder', '', 'intrigu betray deceit murder', 'intrigu betray deceit murder', 'intrigu', 'betray deceit murder', 'betray deceit murder', 'betray', 'deceit murder', 'deceit murder', 'deceit', 'deceit', 'murder', 'shakespearean tragedi juici soap opera', 'shakespearean tragedi juici soap opera', 'shakespearean tragedi', 'shakespearean tragedi', 'shakespearean tragedi', 'shakespearean', 'tragedi', '', 'juici soap opera', 'juici soap opera', 'juici', 'soap opera', 'soap', 'opera']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}